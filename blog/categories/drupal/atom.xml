<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Drupal | PracticalWeb Ltd]]></title>
  <link href="http://www.practicalweb.co.uk/blog/categories/drupal/atom.xml" rel="self"/>
  <link href="http://www.practicalweb.co.uk/"/>
  <updated>2014-11-25T20:03:51+00:00</updated>
  <id>http://www.practicalweb.co.uk/</id>
  <author>
    <name><![CDATA[Sean Burlington]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Drupageddon]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/10/31/drupageddon/"/>
    <updated>2014-10-31T18:30:52+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/10/31/drupageddon</id>
    <content type="html"><![CDATA[<p>Drupal has been in the new today for all the wrong reasons</p>

<p><a href="http://www.bbc.co.uk/news/technology-29846539">Millions of websites hit by Drupal hack attack</a></p>

<p><a href="http://arstechnica.com/security/2014/10/drupal-sites-had-hours-to-patch-before-attacks-started/">Drupal sites had “hours” to patch before attacks started</a></p>

<p><a href="http://www.pcworld.com/article/2841372/drupal-if-you-werent-quick-to-patch-assume-your-site-was-hacked.html">Drupal users: Assume your site was hacked if you didn&rsquo;t apply Oct. 15 patch immediately</a></p>

<p><a href="http://www.forbes.com/sites/thomasbrewster/2014/10/30/did-drupal-drop-the-ball-users-who-didnt-update-within-7-hours-should-assume-theyve-been-hacked/">Did Drupal Drop The Ball? Users Who Didn&rsquo;t Update Within 7 Hours &lsquo;Should Assume They&rsquo;ve Been Hacked&rsquo;</a></p>

<p>The biggest headache for me was the Public Service Announcement <a href="https://www.drupal.org/PSA-2014-003">https://www.drupal.org/PSA-2014-003</a> which is clearly written to alarm users into updating.</p>

<p>We did update our clients site - within 24 hours which at the time seemed pretty good considering the timezones and chaneg control processes involved.</p>

<p>Fortunately we also reload our entire database and other content on each deploy - so even though we took longer than 7 hours to update we consider we are pretty safe (never say 100%) and beyond that we have a lot of other security in place.</p>

<p>However I find myself wondering what else we could have done.</p>

<p>I wish we had a member on the drupal security team - that seems to have helped some people.</p>

<p>I see now there were a couple of (low key) advance notices <a href="https://groups.drupal.org/node/445893">https://groups.drupal.org/node/445893</a> <a href="https://twitter.com/drupalsecurity/status/522128826101669888">https://twitter.com/drupalsecurity/status/522128826101669888</a></p>

<p>I will try to pay better attention to those in the future, but we may also have to enhance our out of hours work, the security annoucment came in at the end of the day - perhaps we will ahve to work overnight another time to review, test, and help the client upgrade.</p>

<p>Hopefully good will come from the thread at <a href="https://groups.drupal.org/node/447468">Follow up Drupageddon responsibly</a></p>

<p>Drupal will need to learn and grow from this.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Migrating From Drupal 5 to Octopress]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/10/21/migrating-from-drupal-5-to-octopress/"/>
    <updated>2014-10-21T15:41:17+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/10/21/migrating-from-drupal-5-to-octopress</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been running this blog (or some version of it) for almost 10 years now.</p>

<p>I write to help clarify my own thoughts, or to note down technical details of a task that I have struggled to figure out. I often found myself coming back and have saved many hours of trying to figure out the same thing again a year or more later.</p>

<p>For a long time this site was running Drupal 5, I set it up at a time when I was getting to know Drupal, starting out as an independant, and had plenty of time to spend on it. At the time this was a very useful excercise, installing lots of modules, and writing some code was good experience. But when Drupal 6 came out and I was busy <a href="/blog/2008/07/18/time-to-upgrade-to-drupal-6}">it wasnt worth upgrading</a>, then when drupal 7 was released and Drupal 5 no longer supported, upgrading was even more difficult as I would have had to upgrade in two steps. Besides Drupal didn&rsquo;t seem like such a good fit for my blog any more.</p>

<p>I don&rsquo;t want to have to apply security updates on a site I&rsquo;m not getting paid for: so a static html site is a great fit for me.</p>

<p>I lose integrated comments, but spam had already killed those for me - I&rsquo;ll try disqus and see how that goes (the need to enable comments in the yaml for each post threw me at first).</p>

<p>Search was useful - but I can grep the source files myself.</p>

<p>I had all sorts of Drupal plugins before - but really I don&rsquo;t think they were very important.</p>

<p>Jekyll seems great, especially because with github&rsquo;s patronage it seems unlikely to become unsupported; and at the end of the day it is just a bunch of simple files so importing to another system should be easy.</p>

<p>Exporting from Drupal 5 needed a <a href="https://github.com/practicalweb/jekyll-import/commit/cfa72281147fd37ce527d2dab1f3ae916e066b04">small patch on the importer</a> without this the categories were seen as some kind of binary object in yaml. The import reads direct from the database, so doesn&rsquo;t run all Drupal&rsquo;s filters and I suspect a drupal export module from drupal would do a much better job. I still need to pull over some old comments and formatting could do with a tidy up, but I need to move to a system that gets me writing new content, and not worry too much about the old.</p>

<p>Jekyll itself didn&rsquo;t use tags in the way I wanted - I find the ability to cross link from one post to similar ones very useful so I am using Octopress which seem to do what I want out of the box.</p>

<p>To get the content in Octopress I just did</p>

<pre><code class="bash">cp jekyll/mysite/_posts/* octopress/source/_posts
</code></pre>

<p>I have switched from pygments highlighter to linguist (this seems to be what github use and supports code highlighting well)</p>

<p>I added a twitter aside for which I just copy pasted the twitter widget into <code>source/_includes/asides/twitter.html</code> and enabled this in _config.yml</p>

<p>I&rsquo;m not a ruby coder, so instaling all the required ruby gems and figuring out how to run a modified version of the jekyll importer took a little while, in the end I think it was just a case of getting all the gems installed that I needed. I didn&rsquo;t blog soon enough!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Static Export of Drupal Site]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/10/14/static-export-of-drupal-site/"/>
    <updated>2014-10-14T00:00:00+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/10/14/static-export-of-drupal-site</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve exported this site from Drupal using wget to create a static html version like</p>

<pre><code>wget  --mirror -p  -e robots=off --base=./ -k -P ./ http://localhost/
</code></pre>

<p>Then rsync to the server and use mod rewrite to retain the paged links like frontpage?page=4</p>

<p>I&rsquo;ve had some trouble getting mod rewrite to work, it seems that getting apache to serve content from filenames containing question marks is tricky.</p>

<p>in apache 2.4 this worked</p>

<pre><code class="ApacheConf">&lt;VirtualHost *:80&gt;
   ServerName practicalweb.localhost
   DocumentRoot /home/sean/rescue/localhost
   RewriteEngine on
   LogLevel alert rewrite:trace3
     &lt;Directory /home/sean/rescue/localhost&gt;
       RewriteCond %{QUERY_STRING} !=&amp;quot;&amp;quot;
       RewriteRule ^(.*) /home/sean/rescue/localhost/$1\%3F%{QUERY_STRING}? [L]

       Options Indexes FollowSymLinks MultiViews
      AllowOverride All
      Require all granted
   &lt;/Directory&gt;
&lt;/VirtualHost&gt;
</code></pre>

<p>But on apache 2.2 (which my server runs I) needed an external redirect</p>

<pre><code class="ApacheConf">&lt;VirtualHost *:80&gt;

  DocumentRoot /var/www/practicalweb
  RewriteEngine on
  RewriteCond %{QUERY_STRING} !=&amp;quot;&amp;quot;
  RewriteRule ^(.*) $1\%3F%{QUERY_STRING}? [last,noescape,R]
    &lt;Directory /&gt;
        Options FollowSymLinks
        AllowOverride None
    &lt;/Directory&gt;
    &lt;Directory /var/www/practicalweb&gt;

        Options None
        AllowOverride None
        Order allow,deny
        allow from all
    &lt;/Directory&gt;
&lt;/VirtualHost&gt;
</code></pre>

<p>It still basically works - but users see a slightly changed URL which isn&rsquo;t quite what I wanted.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Varnish to Cache Authenticated Drupal Pages]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2013/10/15/using-varnish-to-cache-authenticated-drupal-pages/"/>
    <updated>2013-10-15T00:00:00+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2013/10/15/using-varnish-to-cache-authenticated-drupal-pages</id>
    <content type="html"><![CDATA[<p>I have a site which requires users to be logged in, but the pages are not customised. I was playing with a way to cache the content in varnish while still doing an access check. This method uses an access check pages (test.php below) which then uses ESI to load the real, cacheable content.</p>

<p>I&rsquo;ve tried it in a dev env, I&rsquo;m not yet sure if we&rsquo;ll use this in production.</p>

<p>Varnish config</p>

<pre><code class="C">probe checkslash {
    .url = "/robots.txt";
    .interval = 500s;
    .timeout = 10s;
}    

include "backends.vcl";

/** generic config from here down */
sub vcl_recv{

  /* if the drupals are down, this is how long we cache for */
  set req.grace = 6h;

  /* Make sure we direct 443 traffic to the secure drupal */
  if (server.port == 443 ) {
    set req.backend = drpau_ssl_director; 
  } else {
    /* port 80 traffic goes to the correct LB */
    set req.backend = drpau_director;
  }
  # just pass through non-page files, and the login page
  if (req.url ~ "(?i)\.(pdf|asc|dat|txt|doc|xls|ppt|tgz|csv|png|gif|jpeg|jpg|ico|swf|css|js|htc|ejs)(\?.*)?$") {
  } else if (req.url ~ "(?i)(sites/default/files)|(js/)|(/login)" ) { 
  } else if (req.esi_level == 0 ) {
    # pass regular pages to a spoecial url
    set req.url = "/esi" + req.url;
  }
  return (lookup);
}



sub vcl_fetch {

  if (req.url ~ "/esi/" &amp;&amp; req.esi_level == 0 ) {
    set beresp.do_esi = true; /* Do ESI processing               */ 
   }

}
</code></pre>

<p>Then in apache I redirect all requests for pages that come via the esi prefix</p>

<pre><code class="ApacheConf">RewriteRule ^esi/(.*)$ test.php [L]
</code></pre>

<p>and test php is</p>

<pre><code class="PHP">    define('DRUPAL_ROOT', getcwd());
    // We prepare only a minimal bootstrap.
    require_once DRUPAL_ROOT . '/includes/bootstrap.inc';
    drupal_bootstrap(DRUPAL_BOOTSTRAP_SESSION);
    global $user;
    $roles = user_roles();

    if (in_array('anonymous user', $user-&gt;roles)) {
      $uri = preg_replace('#^/esi#', '', $_SERVER[REQUEST_URI]);
      echo "&lt;esi:include src=\"http://$_SERVER[SERVER_NAME]$uri\"/&gt;";
    } else {
        header("Location: https://$_SERVER[SERVER_NAME]/login");
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitor Filesystem for Deletions]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2012/09/28/monitor-filesystem-for-deletions/"/>
    <updated>2012-09-28T00:00:00+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2012/09/28/monitor-filesystem-for-deletions</id>
    <content type="html"><![CDATA[<p>On a project I&#8217;m working on at the moment we have a problem, files are going missing.</p>




<p>We don&#8217;t know which part of the system could be trashing these files (user uploaded images in this case) and they are on a shared filesystem so there are plenty of places to point fingers.</p>




<p>I&#8217;ve discovered a very handy toolset <a href="https://github.com/rvoicilas/inotify-tools/wiki">inotify-tools</a> Which hooks into the linix kernel and allows you to monitor actions like file deletion.</p>




<p>I my case all I need to do right now is monitor the files on each sytem that has access - and I&#8217;m hoping to catch which one does the delete</p>


<p><In my build script is now the code</p></p>

<p><code></p>

<h1>stop monitoring for deletes through the build</h1>

<p>[ -f ~/inotifywait.pid ] &amp;&amp; kill $(cat ~/inotifywait.pid)</p>

<p>git pull
./build.sh</p>

<h1>if the tool is installed - monitor file delets</h1>

<p>which inotifywait &amp;&amp;
{
 nohup inotifywait -mr &ndash;timefmt &lsquo;%d/%m/%y %H:%M&rsquo; &ndash;format &lsquo;%T %w %f %e&rsquo; -e delete /var/www/sites/default/files/ &amp;> ~/build-${JOB_NAME}-$(BUILD_NUMBER)-delete.log  &amp;
 echo $! > ~/inotifywait.pid
}</p>

<p></code></p>

<p>This should create a log of any user files that get deleted between builds</p>
]]></content>
  </entry>
  
</feed>
