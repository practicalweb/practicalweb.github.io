<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Devops | PracticalWeb Ltd]]></title>
  <link href="http://www.practicalweb.co.uk/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://www.practicalweb.co.uk/"/>
  <updated>2015-02-16T20:03:53+00:00</updated>
  <id>http://www.practicalweb.co.uk/</id>
  <author>
    <name><![CDATA[Sean Burlington]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How to Log From Jmeter to Statsd]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/25/how-to-log-from-jmeter-to-statsd/"/>
    <updated>2014-11-25T19:57:40+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/25/how-to-log-from-jmeter-to-statsd</id>
    <content type="html"><![CDATA[<p>In order to log from Jmeter to statsd you need to add <a href="https://github.com/tim-group/java-statsd-client/releases/download/v3.0.1/java-statsd-client-3.0.1.jar">a statsd library</a> to the jmeter /lib path</p>

<p>Then have a beanshell on the thread group setup a statsd object for use by the threads</p>

<p>store this in the props variable - JMeterProperties (class java.util.Properties)</p>

<p>Note that <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Properties.html">the docs</a> say</p>

<blockquote><p>Because Properties inherits from Hashtable, the put and putAll methods can be applied to a Properties object. Their use is strongly discouraged as they allow the caller to insert entries whose keys or values are not Strings. The setProperty method should be used instead. If the store or save method is called on a &ldquo;compromised&rdquo; Properties object that contains a non-String key or value, the call will fail. Similarly, the call to the propertyNames or list method will fail if it is called on a &ldquo;compromised&rdquo; Properties object that contains a non-String key.</p></blockquote>

<p>However I didn&rsquo;t find a better place to put the statsd object yet since the ctx variable is thread specific</p>

<pre><code class="java">import com.timgroup.statsd.StatsDClient;
import com.timgroup.statsd.NonBlockingStatsDClient;

StatsDClient statsd = new NonBlockingStatsDClient("jmeter.test", "statsd.exapmle.com", 8125);

props.put("statsd", statsd);
</code></pre>

<p>Now on the Sampler you want to record data for add a beanshell post processor</p>

<p>You can retrieve the statsd connection from the props variable, and obtain the request time taken from the prev variable which is a org.apache.jmeter.samplers.SampleResult</p>

<p>Once we have the pieces together logging the request time to statsd is simple</p>

<pre><code class="java">
import com.timgroup.statsd.StatsDClient;
import com.timgroup.statsd.NonBlockingStatsDClient;

StatsDClient statsd = (StatsDClient) props.get("statsd");
statsd.recordExecutionTime("loadtime", prev.getTime());
</code></pre>

<p>I&rsquo;ve put an example test plan on github <a href="https://github.com/practicalweb/jmeter-statsd-demo">https://github.com/practicalweb/jmeter-statsd-demo</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Graphite Statsd/bucky and Collectd]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/19/graphite-statsd-slash-bucky-and-collectd/"/>
    <updated>2014-11-19T10:09:23+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/19/graphite-statsd-slash-bucky-and-collectd</id>
    <content type="html"><![CDATA[<blockquote><p>Graphite is a highly scalable real-time graphing system.</p></blockquote>

<p>It took me a while to realise but the data input to graphite is <em>incredibly</em> simple</p>

<p>The message input format is just</p>

<pre><code>metric_path value timestamp\n

So for example, "foo.bar.baz 42 74857843"
</code></pre>

<p>Wow: just a label the number you want to store and the timestamp it relates to.</p>

<p>That&rsquo;s really basic, there is nothing there about what kind of data it is, no difference between something you want to count (say page hits) and a number you want to average (like load)</p>

<p><a href="https://github.com/etsy/statsd/blob/master/docs/graphite.md">Configuring Graphite for StatsD</a> is a <em>very</em> important doc to read if you want to use these tools together.</p>

<p>The default config in graphite keeps data at 1 minute resolution for 1 day <strong>and then discards it</strong> and if you are sending data to graphite every 10 seconds graphite has to figure out how to convert 6 data points (or some nulls and some data) to 1 data point for the minute.</p>

<p>You really need the statsd specific config to ensure counts are not averaged and infrequent data is not dropped.</p>

<p>I needed to install on Centos using just official and EPEL packages, I wanted to use collected to gather system metrics and while version 5 can log direct to graphite version 4 ships with Centos 6.5 and that can&rsquo;t log direct.</p>

<p>In any case I wanted to use statsd to allow easy logging of custom data from production code, the original written by etsy is a node service and probably doesn&rsquo;t run with stock packages on Centos,</p>

<p>Centos does provide a python-bucky package which acts both as a statsd server and as a bridge to collectd.</p>

<p>The full list of packages I needed is</p>

<ul>
<li>graphite-web</li>
<li>graphite-web-selinux</li>
<li>python-carbon</li>
<li>python-whisper</li>
<li>collectd</li>
<li>python-bucky</li>
</ul>


<p>Apache config</p>

<pre><code class="apache">
&lt;VirtualHost *:80&gt;
  ServerName graphite.example.com

  ## Vhost docroot
  DocumentRoot "/var/www/html"
  ## Alias declarations for resources outside the DocumentRoot
  Alias /grafana/ "/var/www/grafana/"
  Alias /media/ "/usr/lib/python2.6/site-packages/django/contrib/admin/media/"



  ## Directories, there should at least be a declaration for /var/www/html


  &lt;Directory "/var/www/html"&gt;
    Options Indexes FollowSymLinks MultiViews
    AllowOverride None
    Order allow,deny
    Allow from all
  &lt;/Directory&gt;

  ## Load additional static includes


  ## Logging
  ErrorLog "/var/log/httpd/graphite.example.com_error.log"
  ServerSignature Off
  CustomLog "/var/log/httpd/graphite.example.com_access.log" combined



  WSGIImportScript /usr/share/graphite/graphite-web.wsgi application-group=%{GLOBAL} process-group=%{GLOBAL}
  WSGIScriptAlias / "/usr/share/graphite/graphite-web.wsgi"

  ## Custom fragment

    &lt;Location "/content/"&gt;
        SetHandler None
    &lt;/Location&gt;

    &lt;Location "/media/"&gt;
        SetHandler None
    &lt;/Location&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>Graphite Config</p>

<p>Storage-schames.conf</p>

<pre><code>[carbon]
pattern = ^carbon\.
retentions = 60:90d

[stats]
pattern = ^stats.*
retentions = 10s:6h,1min:6d,10min:1800d


# unsure if this is redundant - does .* match stats_counts ?
[stats_counts]
pattern = ^stats_counts.*
retentions = 10s:6h,1min:6d,10min:1800d


# collectd 
[com]
pattern = ^com.*
retentions = 10s:6h,1min:6d,10min:1800d

[default_1min_for_1day]
pattern = .*
retentions = 60s:1d
</code></pre>

<p>storage-aggregation.conf</p>

<pre><code>[min]
pattern = \.lower$
xFilesFactor = 0.1
aggregationMethod = min

[max]
pattern = \.upper(_\d+)?$
xFilesFactor = 0.1
aggregationMethod = max

[sum]
pattern = \.sum$
xFilesFactor = 0
aggregationMethod = sum

[count]
pattern = \.count$
xFilesFactor = 0
aggregationMethod = sum

[count_legacy]
pattern = ^stats_counts.*
xFilesFactor = 0
aggregationMethod = sum

[default_average]
pattern = .*
xFilesFactor = 0.3
aggregationMethod = average
</code></pre>

<p>Statsd caught me out with a debug mode that <em>only</em> prints to stdout and doesn&rsquo;t actually log any data to graphite, I expected debug mode to print out data in addition to regular duties.</p>

<p>I did need to make statsd listen on all networks instead of just localhost, and still need to wrap it properly as a service.</p>

<p>Edit collectd.conf to enable the plugins you want, the only problem I had here was collectd silently dying if I had a config error.</p>

<p>You need to setup an initial graphite users database</p>

<p>More details at <a href="http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-4">http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-4</a></p>

<pre><code class="bash">/usr/bin/python /usr/lib/python2.6/site-packages/graphite/manage.py syncdb
</code></pre>

<p>Writing this up now it all seems quite simple - but I haven&rsquo;t really found it so, I think the main problem has been understanding what graphite is actually doing, and not taking the trouble to optimise that config as a first step.</p>

<p>Pages I found useful</p>

<ul>
<li><a href="https://kevinmccarthy.org/blog/2013/07/18/10-things-i-learned-deploying-graphite/">https://kevinmccarthy.org/blog/2013/07/18/10-things-i-learned-deploying-graphite/</a></li>
<li><a href="http://blog.pkhamre.com/2012/07/24/understanding-statsd-and-graphite/">http://blog.pkhamre.com/2012/07/24/understanding-statsd-and-graphite/</a></li>
<li><a href="http://statsd.readthedocs.org/en/latest/types.html#counters">http://statsd.readthedocs.org/en/latest/types.html#counters</a></li>
<li><a href="http://code.hootsuite.com/accurate-counting-with-graphite-and-statsd/">http://code.hootsuite.com/accurate-counting-with-graphite-and-statsd/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grafana]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/19/grafana/"/>
    <updated>2014-11-19T10:07:55+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/19/grafana</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been playing with some new toys.</p>

<p>What motivated me was a desire to be better able to interpret load test data and performance metrics.</p>

<p>I love graphs, for me the visualisation they provide allows me to recognise patterns and figure out cause/effects massively faster than any other way.</p>

<p>In the past I&rsquo;ve mainly relied on Munin which is very easy to setup, and I&rsquo;ve even customised graphs. My most successful case was when two servers in a pool of four kept falling down, by graphing apache hits per second and severer load for all for servers on the same page - it provided convincing proof that the two servers which fell down did so under no extra load and at the exact same moment. It later turned out these two were VMs on the same host OS which was having previously unnoticed problems.</p>

<p>This visualisation transformed a conversation from one of what could or couldn&rsquo;t be wrong to acceptance and how to fix it.</p>

<p>But with Munin I had to define the graph and then collect the data - I had to wait for another outage.</p>

<p>I wanted to be able to compose graphs on the fly to test hypotheses with existing data - grab the data now and define the graphs to visualise what I want to see after the fact.</p>

<p>Enter <a href="http://play.grafana.org/">Grafana</a> I just love this tool, it allows me to compose graphs entirely on the fly, mixing and matching any data I want on the same graph, or multiple graphs on the same page.</p>

<p>With the <a href="http://graphite.readthedocs.org/en/latest/functions.html#graphite.render.functions.timeShift">timeshift</a> function I can even put say this weeks and last weeks data on the same graph for easy comparison.</p>

<p>I hope to work on some screenshots and maybe screencaps - the tool is so interactive it&rsquo;s hard to explain - for now go an play with it.</p>

<p>Grafana works by calling the json API of graphite-web, one thing that threw me at first was the <a href="http://grafana.org/docs/#graphite-&amp;-elasticsearch-setup-example">initial config example</a></p>

<pre><code class="json">datasources: {
  graphite: {
    type: 'graphite',
    url: "http://my.graphite.server.com:8080",
  },
},
</code></pre>

<p>I wasn&rsquo;t sure which server component I was meant to be connecting to on 8080, this is just the regular graphite-web service from apache - in my case on port 80.</p>

<p>It&rsquo;s also worth noting that <a href="graphite%20cannot%20exist%20in%20a%20subdirctory">https://github.com/graphite-project/graphite-web/issues/223</a> at least not for the version I am running.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing for Ops]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/10/14/developing-for-ops/"/>
    <updated>2014-10-14T00:00:00+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/10/14/developing-for-ops</id>
    <content type="html"><![CDATA[<p>We often work on large websites with strict change control practices and scheduled release cycles. Sometimes we also hand over the systems to the client for production and don’t have direct access ourselves.</p>

<p>Some bugs have a nasty habit of only occurring in production, this may be due to high load, odd/old browsers, changes in data, or just because test scenarios don’t cover every eventuality.</p>

<p>What this means is that when we have a bug in production we can only understand it through the error logging we have already built into the system. If we need to put in place additional logging we usually lose the chance of actually fixing the bug for another release cycle.</p>

<p>One of the real arts in this flow of development is to be pessimistic enough to assume that somehow something is going to go wrong, to remember that the people who see the bug will not be the developers who know the code, and that at this point (unlike during dev) we will have very limited access to the systems we might want to debug.</p>

<p>One temptation is to log everything - but you soon find that doesn’t scale.</p>

<p>The art of error messages is a bit like the art of commenting - especially for those errors that should never happen. You often don’t need to say exactly what went wrong, hopefully your compiler or runtime engine will do this along with a stacktrace or at least a line number. You need to say what it means to have this error - especially if it indicates a breakdown in business logic. It also helps to raise errors as early in the code flow as possible.</p>

<p>When working on a large project with multiple teams it is especially helpful for errors to make clear whenever possible which team the bug belongs to. Clear error data like this can really cut down on the politics that can accompany a production bug and radically reduce the time to fix.</p>

<p>For example let’s imagine that we are developing a website, we are responsible for the shopfront but we obtain product data from a feed. As well as all the bugs that can occur in our code there are likely to be a whole host of possible problems with the incoming data.</p>

<p>What if we receive a null instead of the agreed object, what if the price is non numeric (or zero, or negative), what if an expected field is missing?</p>

<p>You might display a product with zero price, fail to display it, or perhaps you do catch an error but the log just says something like “Notice:  Trying to get property of non-object”. The bug gets reported to the front end team - because that’s where the error appears. The front end team can’t see the production data.</p>

<p>The politics here is that teams often blame each other, developers are generally optimistic that their code is good and pessimistic about other teams code. Therefore bugs get thrown over the wall too quick and then get thrown back - leaving bugs bouncing about with no fix.</p>

<p>Now imagine you have explicit validation at the point you load third party data (or any place you have a boundary of responsibility like this). You log an error that points directly to the data feed, hopefully with the actual data that is wrong, perhaps even logging the request/response pair that led to it. This time you can give the data team enough info that they can quickly identify the problem. Conversely if you have missing products and no data errors - the impossible has happened - there is a bug in your own code. Now you get to be the hero and fix it.</p>

<p>Remember, in development (where developers spend 95%) of their time this bug would be trivial, the developer would see the error, know which bit of code it related to, be able to view the data feed, and report the bug back to the data team. The trick is to remember it won’t be like this in production.</p>

<p>In my experience it is well worth spending a chunk of time up front writing good generic error routines, that capture as much detail as possible, and 5 or 10 minutes every day looking at stubbed out error routines.</p>

<p>This may add up to a non-trivial time investment - but you only have to save a few minor production bugs to get paid back plenty.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vagrant / Puppet Project to Setup a RPM Build Server and Custom Yum Repository]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2012/11/24/vagrant-puppet-project-to-setup-a-rpm-build-server-and-custom-yum-repository/"/>
    <updated>2012-11-24T00:00:00+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2012/11/24/vagrant-puppet-project-to-setup-a-rpm-build-server-and-custom-yum-repository</id>
    <content type="html"><![CDATA[<p>I&#8217;ve published a project on github <a href="https://github.com/practicalweb/vagrant-rpmbuild">https://github.com/practicalweb/vagrant-rpmbuild</a></p>




<p>The project contains a Vagrant config file, and Puppet manifests that together with an appropriate basebox will create a VM setup to build RPMS and host them on a Custom Yum repository</p>




<p>To run this</p>




<ol>
<li><p>Install vagrant <a href="http://vagrantup.com/">http://vagrantup.com/</a> (on Ubuntu just <code>apt-get install vagrant</code>)</p></li>
<li><p>Install Virtualbox <a href="https://www.virtualbox.org/wiki/Downloads">https://www.virtualbox.org/wiki/Downloads</a> (again on Ubuntu <code>apt-get install virtualbox</code>)</p></li>
<li><p>Clone this reporitory <code>git clone git@github.com:practicalweb/vagrant-rpmbuild.git</code></p></li>
<li><p>run <code>vagrant up</code> from the root of your cloned repository (NB the first time you do the a 600Mb base image will be downloaded)</p></li>
<li><p>run <code>vagrant ssh</code> to connect to the new VM  </p></li>
<li><p>To build the demo rpm and publish it locally run <code>/vagrant/build-rpm.sh</code> the key password is &#8216;secret&#8217;</p></li>
<li><p>To install the demo package on the VM run <code>sudo yum install demo</code></p></li>
</ol>


<p>There is a Vagrant port forwarding rule, and firewall setup to allow the yum repo to be accessed on the host machine as http://localhos:8088/repo</p>




<p>This project is intended as documentation of how to setup this build environment, and as a starting point for further customisation, I&#8217;m sure it isn&#8217;t perfect, I hope it is useful.</p>




<p>It&#8217;s all released under GPL with no promise that it is fot for any purpose - see LICENCE.txt </p>




<p>I&#8217;ve tried to group the code logically, there are 4 modules</p>




<dl>
<dt>base</dt>
    <dd>This contains some generic stuff, pulling in a couple of packages not in the minimal centos install but that I find essential.</dd><dd>
    </dd><dd>The idea is that I would use this base module on every server I setup.</dd>

  

<dt>rpmbuild</dt>
    <dd>Just what is needed to actually build the RPMs</dd><dd>
  
  </dd>

<dt>tomyumrepo</dt>
     <dd>Just what is needed to serve a custom yum repository, the packages could be built elsewhere</dd>
  <dt>usemyrepo</dt>
     <dd>Config to setup a machine to consume yum packages.</dd>
     <dd>This could be added to the setup for any machine that needs to use the custom packages</dd>
</dl>


<p>I&#8217;ve included a minimal RPM project to get things rolling, it just installs a single text file.</p>




<p>I&#8217;ve built a GPG key to sign packages with, and also included a script ( generate-gpg-key.sh ) which shows how to generate a new one, edit this file to make your own key.</p>




<p>The base box I&#8217;ve defined is a minimal install of CentOS 6.3 (64 bit) with the dependencies required for vagrant.</p>




<p>Base boxes are quite a heavy download, but you only need to do it once and then you can have as many VMs as you want based on them, because the base is minimal and all extra config is done in puppet each of these VMs can serve a very differnt purpose - just by changing the Vagrantfile and puppet config.</p>




<p>The Vagrantfile runs puppet in standalone mode, but the modules <em>should</em> work with a client/server Puppet setup - so hopefully migrating the Vagrant setup to any Puppet manged system should be easy.</p>

]]></content>
  </entry>
  
</feed>
