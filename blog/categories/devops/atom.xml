<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Devops | PracticalWeb Ltd]]></title>
  <link href="http://www.practicalweb.co.uk/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://www.practicalweb.co.uk/"/>
  <updated>2015-03-11T22:20:35+00:00</updated>
  <id>http://www.practicalweb.co.uk/</id>
  <author>
    <name><![CDATA[Sean Burlington]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[First Steps With Ansible and Docker]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2015/02/18/first-steps-with-ansible-and-docker/"/>
    <updated>2015-02-18T14:04:59+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2015/02/18/first-steps-with-ansible-and-docker</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been using puppet and vagrant for a while, due to client choices we&rsquo;re switching to ansible which I&rsquo;m less familiar with - and Docker has been on my to learn list for a while.</p>

<p>I love vagrant - being able to bring up a VM locally that matches the production servers to a good degree is just brilliant, and being able to repeat deploys is invaluable in testing process.</p>

<p>The limitation with VMs is that each one takes a lot of resources, and is slow to build.</p>

<p>Linux containers are <em>much</em> lighter weight - being faster to create and using much less system resource to run, I&rsquo;m hoping to be able to run more servers at once inside my laptop.</p>

<p>There is a nice quick demo of docker <a href="https://www.docker.com/tryit/">https://www.docker.com/tryit/</a></p>

<p>The steps below cover installing ansible and docker, building a simple docker image, and then using an ansible playbook to both create a container and then connect to that container. I just run a hello world at that point - but from there running any ansible code should be simple.</p>

<hr />

<p>On Ubuntu I installed the latest version via ppa following the notes from <a href="https://docs.docker.com/installation/ubuntulinux/">https://docs.docker.com/installation/ubuntulinux/</a></p>

<pre><code class="bash "># add the Docker repository key to your local keychain.
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9
# Add the Docker repository to your apt sources list, update and install the lxc-docker package.
# You may receive a warning that the package isn't trusted. Answer yes to continue installation.

sudo sh -c "echo deb https://get.docker.com/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list"
sudo apt-get update
sudo apt-get install lxc-docker


# To verify that everything has worked as expected:

sudo docker run -i -t ubuntu /bin/bash
</code></pre>

<p>I also installed docker-py <a href="https://github.com/docker/docker-py">https://github.com/docker/docker-py</a></p>

<pre><code class="bash">sudo pip install docker-py
</code></pre>

<p>This is required for the docker module in ansible which allows running docker commands from an ansible playbook, I probably don&rsquo;t need this right away - but later I want to be able to manage multiple docker containers on remote servers.</p>

<p>I installed ansible from git, following the instructions at <a href="http://docs.ansible.com/intro_installation.html#getting-ansible">http://docs.ansible.com/intro_installation.html#getting-ansible</a></p>

<pre><code class="bash ">
git clone git://github.com/ansible/ansible.git --recursive
cd ./ansible
source ./hacking/env-setup

#Ansible also uses the following Python modules that need to be installed:

sudo pip install paramiko PyYAML Jinja2 httplib2
</code></pre>

<p>Setup an Inventory file
<code>bash
echo "localhost ansible_connection=local" &gt; ~/ansible_hosts
export ANSIBLE_HOSTS=~/ansible_hosts
</code></p>

<p>test with a ping command:
<code>bash
ansible all -m ping
</code></p>

<p>Those last steps are a slight variation on the official docs as I didn&rsquo;t want to use ssh locally - preferring the local connection which doesn&rsquo;t need passwords or keys to work, I&rsquo;ll come to that later.</p>

<p>I created a Dockerfile which builds me a base image that just has</p>

<ul>
<li>sshd running</li>
<li>the ssh port exposed</li>
<li>ansible user added</li>
<li>passwordless sudo for ansible user</li>
<li>an authorised key for ansible user</li>
</ul>


<p>The file is</p>

<pre><code class="Dockerfile"># base
#
# VERSION               0.0.1

FROM centos:6
MAINTAINER Sean Burlington &lt;sean@practicalweb.co.uk&gt;

# setup sshd,  ensuring it runs through regular configs once - this does some initial setup
RUN yum -y update &amp;&amp; yum -y install openssh-server
RUN service sshd start &amp;&amp; service sshd stop

# create ansible user with sudo and public key
RUN yum -y install sudo
RUN useradd ansible
RUN echo 'ansible:D\N5Vlucg7,JlUhiDb&lt;N' | chpasswd
ADD etc/sudoers/ansible /etc/sudoers.d/
RUN mkdir -p /home/ansible/.ssh/
ADD home/ansible/.ssh/authorized_keys /home/ansible/.ssh/
RUN chown -R ansible:ansible /home/ansible/ &amp;&amp; chmod 700 /home/ansible/.ssh/ &amp;&amp; chmod 600 /home/ansible/.ssh/authorized_keys


# set example env variable that will be visible in users shell
RUN echo "export VISIBLE=now" &gt;&gt; /etc/profile

# run sshd and expose it 
EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]
</code></pre>

<p>get this file and supporting code by</p>

<pre><code class="bash ">git clone https://github.com/practicalweb/docker-ansible.git
cd docker-ansible
</code></pre>

<p>Note that I don&rsquo;t include my public key there (it is gitignored)</p>

<p>copy your by something like
<code>bash
cp ~/.ssh/id_rsa.pub base-docker/home/ansible/.ssh/authorized_keys
</code></p>

<p>build the image
<code>
sudo docker build -t base base-docker/
</code></p>

<p>I wrote a playbook that creates a container from the image, adds this host to the ansible inventory and then runs an ansible command to it</p>

<pre><code class="YAML"># Docker / ansible hello world


# Create a a docker container on localhost (this has an ssh server in the image)
- hosts: localhost
  sudo: yes
  tasks:
  - name: start container 
    docker: image=base hostname=test name=test detach=False 

# add container(s) to the hosts inventory
  - name: add new hosts to inventory
    add_host: hostname=""
      groups=docker
      ansible_ssh_host=""
      ansible_ssh_port=22
    when: item.State.Running == True
    with_items: docker_containers


# Now we can run ansible on the dockers container(s)
- hosts: docker
  sudo: yes
  remote_user: ansible
  tasks: 
    - name: hello
      shell: echo "hello world" 
</code></pre>

<p>run it like</p>

<pre><code class="bash">export ANSIBLE_HOST_KEY_CHECKING=False
ansible-playbook  --ask-sudo-pass docker1.playbook
</code></pre>

<p>I turn off host key checking since this is a new host and will always fail</p>

<p>To clean up after creating containers - or you end up with lots of mess&hellip;</p>

<p>To stop all docker containers</p>

<pre><code class="bash ">sudo docker stop $(sudo docker ps -a -q)
</code></pre>

<p>To remove all docker containers</p>

<pre><code class="bash">sudo docker rm $(sudo docker ps -a -q)
</code></pre>

<p>Well now I can build a base image, create an instance of it as a container, and run ansible there.</p>

<p>Next steps are to run a more meaningful ansible playbook to setup my applications, and to link containers together so that apps can connect.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Log From Jmeter to Statsd]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/25/how-to-log-from-jmeter-to-statsd/"/>
    <updated>2014-11-25T19:57:40+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/25/how-to-log-from-jmeter-to-statsd</id>
    <content type="html"><![CDATA[<p>In order to log from Jmeter to statsd you need to add <a href="https://github.com/tim-group/java-statsd-client/releases/download/v3.0.1/java-statsd-client-3.0.1.jar">a statsd library</a> to the jmeter /lib path</p>

<p>Then have a beanshell on the thread group setup a statsd object for use by the threads</p>

<p>store this in the props variable - JMeterProperties (class java.util.Properties)</p>

<p>Note that <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Properties.html">the docs</a> say</p>

<blockquote><p>Because Properties inherits from Hashtable, the put and putAll methods can be applied to a Properties object. Their use is strongly discouraged as they allow the caller to insert entries whose keys or values are not Strings. The setProperty method should be used instead. If the store or save method is called on a &ldquo;compromised&rdquo; Properties object that contains a non-String key or value, the call will fail. Similarly, the call to the propertyNames or list method will fail if it is called on a &ldquo;compromised&rdquo; Properties object that contains a non-String key.</p></blockquote>

<p>However I didn&rsquo;t find a better place to put the statsd object yet since the ctx variable is thread specific</p>

<pre><code class="java">import com.timgroup.statsd.StatsDClient;
import com.timgroup.statsd.NonBlockingStatsDClient;

StatsDClient statsd = new NonBlockingStatsDClient("jmeter.test", "statsd.exapmle.com", 8125);

props.put("statsd", statsd);
</code></pre>

<p>Now on the Sampler you want to record data for add a beanshell post processor</p>

<p>You can retrieve the statsd connection from the props variable, and obtain the request time taken from the prev variable which is a org.apache.jmeter.samplers.SampleResult</p>

<p>Once we have the pieces together logging the request time to statsd is simple</p>

<pre><code class="java">
import com.timgroup.statsd.StatsDClient;
import com.timgroup.statsd.NonBlockingStatsDClient;

StatsDClient statsd = (StatsDClient) props.get("statsd");
statsd.recordExecutionTime("loadtime", prev.getTime());
</code></pre>

<p>I&rsquo;ve put an example test plan on github <a href="https://github.com/practicalweb/jmeter-statsd-demo">https://github.com/practicalweb/jmeter-statsd-demo</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Graphite Statsd/bucky and Collectd]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/19/graphite-statsd-slash-bucky-and-collectd/"/>
    <updated>2014-11-19T10:09:23+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/19/graphite-statsd-slash-bucky-and-collectd</id>
    <content type="html"><![CDATA[<blockquote><p>Graphite is a highly scalable real-time graphing system.</p></blockquote>

<p>It took me a while to realise but the data input to graphite is <em>incredibly</em> simple</p>

<p>The message input format is just</p>

<pre><code>metric_path value timestamp\n

So for example, "foo.bar.baz 42 74857843"
</code></pre>

<p>Wow: just a label the number you want to store and the timestamp it relates to.</p>

<p>That&rsquo;s really basic, there is nothing there about what kind of data it is, no difference between something you want to count (say page hits) and a number you want to average (like load)</p>

<p><a href="https://github.com/etsy/statsd/blob/master/docs/graphite.md">Configuring Graphite for StatsD</a> is a <em>very</em> important doc to read if you want to use these tools together.</p>

<p>The default config in graphite keeps data at 1 minute resolution for 1 day <strong>and then discards it</strong> and if you are sending data to graphite every 10 seconds graphite has to figure out how to convert 6 data points (or some nulls and some data) to 1 data point for the minute.</p>

<p>You really need the statsd specific config to ensure counts are not averaged and infrequent data is not dropped.</p>

<p>I needed to install on Centos using just official and EPEL packages, I wanted to use collected to gather system metrics and while version 5 can log direct to graphite version 4 ships with Centos 6.5 and that can&rsquo;t log direct.</p>

<p>In any case I wanted to use statsd to allow easy logging of custom data from production code, the original written by etsy is a node service and probably doesn&rsquo;t run with stock packages on Centos,</p>

<p>Centos does provide a python-bucky package which acts both as a statsd server and as a bridge to collectd.</p>

<p>The full list of packages I needed is</p>

<ul>
<li>graphite-web</li>
<li>graphite-web-selinux</li>
<li>python-carbon</li>
<li>python-whisper</li>
<li>collectd</li>
<li>python-bucky</li>
</ul>


<p>Apache config</p>

<pre><code class="apache">
&lt;VirtualHost *:80&gt;
  ServerName graphite.example.com

  ## Vhost docroot
  DocumentRoot "/var/www/html"
  ## Alias declarations for resources outside the DocumentRoot
  Alias /grafana/ "/var/www/grafana/"
  Alias /media/ "/usr/lib/python2.6/site-packages/django/contrib/admin/media/"



  ## Directories, there should at least be a declaration for /var/www/html


  &lt;Directory "/var/www/html"&gt;
    Options Indexes FollowSymLinks MultiViews
    AllowOverride None
    Order allow,deny
    Allow from all
  &lt;/Directory&gt;

  ## Load additional static includes


  ## Logging
  ErrorLog "/var/log/httpd/graphite.example.com_error.log"
  ServerSignature Off
  CustomLog "/var/log/httpd/graphite.example.com_access.log" combined



  WSGIImportScript /usr/share/graphite/graphite-web.wsgi application-group=%{GLOBAL} process-group=%{GLOBAL}
  WSGIScriptAlias / "/usr/share/graphite/graphite-web.wsgi"

  ## Custom fragment

    &lt;Location "/content/"&gt;
        SetHandler None
    &lt;/Location&gt;

    &lt;Location "/media/"&gt;
        SetHandler None
    &lt;/Location&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>Graphite Config</p>

<p>Storage-schames.conf</p>

<pre><code>[carbon]
pattern = ^carbon\.
retentions = 60:90d

[stats]
pattern = ^stats.*
retentions = 10s:6h,1min:6d,10min:1800d


# unsure if this is redundant - does .* match stats_counts ?
[stats_counts]
pattern = ^stats_counts.*
retentions = 10s:6h,1min:6d,10min:1800d


# collectd 
[com]
pattern = ^com.*
retentions = 10s:6h,1min:6d,10min:1800d

[default_1min_for_1day]
pattern = .*
retentions = 60s:1d
</code></pre>

<p>storage-aggregation.conf</p>

<pre><code>[min]
pattern = \.lower$
xFilesFactor = 0.1
aggregationMethod = min

[max]
pattern = \.upper(_\d+)?$
xFilesFactor = 0.1
aggregationMethod = max

[sum]
pattern = \.sum$
xFilesFactor = 0
aggregationMethod = sum

[count]
pattern = \.count$
xFilesFactor = 0
aggregationMethod = sum

[count_legacy]
pattern = ^stats_counts.*
xFilesFactor = 0
aggregationMethod = sum

[default_average]
pattern = .*
xFilesFactor = 0.3
aggregationMethod = average
</code></pre>

<p>Statsd caught me out with a debug mode that <em>only</em> prints to stdout and doesn&rsquo;t actually log any data to graphite, I expected debug mode to print out data in addition to regular duties.</p>

<p>I did need to make statsd listen on all networks instead of just localhost, and still need to wrap it properly as a service.</p>

<p>Edit collectd.conf to enable the plugins you want, the only problem I had here was collectd silently dying if I had a config error.</p>

<p>You need to setup an initial graphite users database</p>

<p>More details at <a href="http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-4">http://obfuscurity.com/2012/04/Unhelpful-Graphite-Tip-4</a></p>

<pre><code class="bash">/usr/bin/python /usr/lib/python2.6/site-packages/graphite/manage.py syncdb
</code></pre>

<p>Writing this up now it all seems quite simple - but I haven&rsquo;t really found it so, I think the main problem has been understanding what graphite is actually doing, and not taking the trouble to optimise that config as a first step.</p>

<p>Pages I found useful</p>

<ul>
<li><a href="https://kevinmccarthy.org/blog/2013/07/18/10-things-i-learned-deploying-graphite/">https://kevinmccarthy.org/blog/2013/07/18/10-things-i-learned-deploying-graphite/</a></li>
<li><a href="http://blog.pkhamre.com/2012/07/24/understanding-statsd-and-graphite/">http://blog.pkhamre.com/2012/07/24/understanding-statsd-and-graphite/</a></li>
<li><a href="http://statsd.readthedocs.org/en/latest/types.html#counters">http://statsd.readthedocs.org/en/latest/types.html#counters</a></li>
<li><a href="http://code.hootsuite.com/accurate-counting-with-graphite-and-statsd/">http://code.hootsuite.com/accurate-counting-with-graphite-and-statsd/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grafana]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/11/19/grafana/"/>
    <updated>2014-11-19T10:07:55+00:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/11/19/grafana</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been playing with some new toys.</p>

<p>What motivated me was a desire to be better able to interpret load test data and performance metrics.</p>

<p>I love graphs, for me the visualisation they provide allows me to recognise patterns and figure out cause/effects massively faster than any other way.</p>

<p>In the past I&rsquo;ve mainly relied on Munin which is very easy to setup, and I&rsquo;ve even customised graphs. My most successful case was when two servers in a pool of four kept falling down, by graphing apache hits per second and severer load for all for servers on the same page - it provided convincing proof that the two servers which fell down did so under no extra load and at the exact same moment. It later turned out these two were VMs on the same host OS which was having previously unnoticed problems.</p>

<p>This visualisation transformed a conversation from one of what could or couldn&rsquo;t be wrong to acceptance and how to fix it.</p>

<p>But with Munin I had to define the graph and then collect the data - I had to wait for another outage.</p>

<p>I wanted to be able to compose graphs on the fly to test hypotheses with existing data - grab the data now and define the graphs to visualise what I want to see after the fact.</p>

<p>Enter <a href="http://play.grafana.org/">Grafana</a> I just love this tool, it allows me to compose graphs entirely on the fly, mixing and matching any data I want on the same graph, or multiple graphs on the same page.</p>

<p>With the <a href="http://graphite.readthedocs.org/en/latest/functions.html#graphite.render.functions.timeShift">timeshift</a> function I can even put say this weeks and last weeks data on the same graph for easy comparison.</p>

<p>I hope to work on some screenshots and maybe screencaps - the tool is so interactive it&rsquo;s hard to explain - for now go an play with it.</p>

<p>Grafana works by calling the json API of graphite-web, one thing that threw me at first was the <a href="http://grafana.org/docs/#graphite-&amp;-elasticsearch-setup-example">initial config example</a></p>

<pre><code class="json">datasources: {
  graphite: {
    type: 'graphite',
    url: "http://my.graphite.server.com:8080",
  },
},
</code></pre>

<p>I wasn&rsquo;t sure which server component I was meant to be connecting to on 8080, this is just the regular graphite-web service from apache - in my case on port 80.</p>

<p>It&rsquo;s also worth noting that <a href="graphite%20cannot%20exist%20in%20a%20subdirctory">https://github.com/graphite-project/graphite-web/issues/223</a> at least not for the version I am running.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing for Ops]]></title>
    <link href="http://www.practicalweb.co.uk/blog/2014/10/14/developing-for-ops/"/>
    <updated>2014-10-14T00:00:00+01:00</updated>
    <id>http://www.practicalweb.co.uk/blog/2014/10/14/developing-for-ops</id>
    <content type="html"><![CDATA[<p>We often work on large websites with strict change control practices and scheduled release cycles. Sometimes we also hand over the systems to the client for production and don’t have direct access ourselves.</p>

<p>Some bugs have a nasty habit of only occurring in production, this may be due to high load, odd/old browsers, changes in data, or just because test scenarios don’t cover every eventuality.</p>

<p>What this means is that when we have a bug in production we can only understand it through the error logging we have already built into the system. If we need to put in place additional logging we usually lose the chance of actually fixing the bug for another release cycle.</p>

<p>One of the real arts in this flow of development is to be pessimistic enough to assume that somehow something is going to go wrong, to remember that the people who see the bug will not be the developers who know the code, and that at this point (unlike during dev) we will have very limited access to the systems we might want to debug.</p>

<p>One temptation is to log everything - but you soon find that doesn’t scale.</p>

<p>The art of error messages is a bit like the art of commenting - especially for those errors that should never happen. You often don’t need to say exactly what went wrong, hopefully your compiler or runtime engine will do this along with a stacktrace or at least a line number. You need to say what it means to have this error - especially if it indicates a breakdown in business logic. It also helps to raise errors as early in the code flow as possible.</p>

<p>When working on a large project with multiple teams it is especially helpful for errors to make clear whenever possible which team the bug belongs to. Clear error data like this can really cut down on the politics that can accompany a production bug and radically reduce the time to fix.</p>

<p>For example let’s imagine that we are developing a website, we are responsible for the shopfront but we obtain product data from a feed. As well as all the bugs that can occur in our code there are likely to be a whole host of possible problems with the incoming data.</p>

<p>What if we receive a null instead of the agreed object, what if the price is non numeric (or zero, or negative), what if an expected field is missing?</p>

<p>You might display a product with zero price, fail to display it, or perhaps you do catch an error but the log just says something like “Notice:  Trying to get property of non-object”. The bug gets reported to the front end team - because that’s where the error appears. The front end team can’t see the production data.</p>

<p>The politics here is that teams often blame each other, developers are generally optimistic that their code is good and pessimistic about other teams code. Therefore bugs get thrown over the wall too quick and then get thrown back - leaving bugs bouncing about with no fix.</p>

<p>Now imagine you have explicit validation at the point you load third party data (or any place you have a boundary of responsibility like this). You log an error that points directly to the data feed, hopefully with the actual data that is wrong, perhaps even logging the request/response pair that led to it. This time you can give the data team enough info that they can quickly identify the problem. Conversely if you have missing products and no data errors - the impossible has happened - there is a bug in your own code. Now you get to be the hero and fix it.</p>

<p>Remember, in development (where developers spend 95%) of their time this bug would be trivial, the developer would see the error, know which bit of code it related to, be able to view the data feed, and report the bug back to the data team. The trick is to remember it won’t be like this in production.</p>

<p>In my experience it is well worth spending a chunk of time up front writing good generic error routines, that capture as much detail as possible, and 5 or 10 minutes every day looking at stubbed out error routines.</p>

<p>This may add up to a non-trivial time investment - but you only have to save a few minor production bugs to get paid back plenty.</p>
]]></content>
  </entry>
  
</feed>
